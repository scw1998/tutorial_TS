{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiwon/miniconda3/envs/temporary/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, NBeats, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import SMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>value</th>\n",
       "      <th>static</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.097796</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.144397</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.177954</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>99</td>\n",
       "      <td>395</td>\n",
       "      <td>-5.587069</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>99</td>\n",
       "      <td>396</td>\n",
       "      <td>-4.986342</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>99</td>\n",
       "      <td>397</td>\n",
       "      <td>-5.630228</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>99</td>\n",
       "      <td>398</td>\n",
       "      <td>-5.745145</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>99</td>\n",
       "      <td>399</td>\n",
       "      <td>-4.690036</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       series  time_idx     value  static       date\n",
       "0           0         0 -0.000000       2 2020-01-01\n",
       "1           0         1 -0.046501       2 2020-01-02\n",
       "2           0         2 -0.097796       2 2020-01-03\n",
       "3           0         3 -0.144397       2 2020-01-04\n",
       "4           0         4 -0.177954       2 2020-01-05\n",
       "...       ...       ...       ...     ...        ...\n",
       "39995      99       395 -5.587069       2 2021-01-30\n",
       "39996      99       396 -4.986342       2 2021-01-31\n",
       "39997      99       397 -5.630228       2 2021-02-01\n",
       "39998      99       398 -5.745145       2 2021-02-02\n",
       "39999      99       399 -4.690036       2 2021-02-03\n",
       "\n",
       "[40000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_ar_data(seasonality=10.0, timesteps=400, n_series=100, seed=42)\n",
    "data[\"static\"] = 2\n",
    "data[\"date\"] = pd.Timestamp(\"2020-01-01\") + pd.to_timedelta(data.time_idx, \"D\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>value</th>\n",
       "      <th>static</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.097796</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.144397</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.177954</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>397</td>\n",
       "      <td>2.537928</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "      <td>2.354053</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>2.323488</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046051</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     series  time_idx     value  static       date\n",
       "0         0         0 -0.000000       2 2020-01-01\n",
       "1         0         1 -0.046501       2 2020-01-02\n",
       "2         0         2 -0.097796       2 2020-01-03\n",
       "3         0         3 -0.144397       2 2020-01-04\n",
       "4         0         4 -0.177954       2 2020-01-05\n",
       "..      ...       ...       ...     ...        ...\n",
       "397       0       397  2.537928       2 2021-02-01\n",
       "398       0       398  2.354053       2 2021-02-02\n",
       "399       0       399  2.323488       2 2021-02-03\n",
       "400       1         0 -0.000000       2 2020-01-01\n",
       "401       1         1 -0.046051       2 2020-01-02\n",
       "\n",
       "[402 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet, NBeats, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE\n",
    "from pytorch_forecasting.models import NBeatsModel\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('electricity.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(scaled_df) * 0.8)\n",
    "train_data, test_data = scaled_df[:train_size], scaled_df[train_size:]\n",
    "\n",
    "# Define the dataset parameters\n",
    "max_encoder_length = 168  # use 7 days of history\n",
    "max_prediction_length = 24  # predict 24 hours into the future\n",
    "\n",
    "# Create the TimeSeriesDataSet for training\n",
    "training = TimeSeriesDataSet(\n",
    "    train_data.reset_index(),\n",
    "    time_idx=\"date\",\n",
    "    target=\"OT\",  # replace with the appropriate target column name\n",
    "    group_ids=[\"date\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=list(train_data.columns),\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"OT\"],  # replace with the appropriate target column name\n",
    "    target_normalizer=GroupNormalizer(groups=[\"date\"], transformation=\"softplus\"),\n",
    ")\n",
    "\n",
    "# Create the DataLoader for training\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=128, num_workers=4)\n",
    "\n",
    "# Define the N-BEATS model\n",
    "nbeats = NBeatsModel.from_dataset(\n",
    "    training,\n",
    "    learning_rate=3e-3,\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    weight_decay=1e-2,\n",
    "    widths=[512, 512, 512, 512],\n",
    "    backcast_loss_ratio=0.1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=30, gradient_clip_val=0.1)\n",
    "trainer.fit(\n",
    "    nbeats,\n",
    "    train_dataloaders=train_dataloader,\n",
    ")\n",
    "\n",
    "# Prepare test data similarly\n",
    "test = TimeSeriesDataSet.from_dataset(training, test_data.reset_index(), predict=True, stop_randomization=True)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_dataloader = test.to_dataloader(train=False, batch_size=128, num_workers=4)\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(nbeats, test_dataloaders=test_dataloader)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "scaled_predictions = scaler.inverse_transform(predictions.numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = RMSE()(predictions, test_data[\"OT\"].values)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloaders\n",
    "max_encoder_length = 60\n",
    "max_prediction_length = 20\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "context_length = max_encoder_length\n",
    "prediction_length = max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"OT\",\n",
    "    categorical_encoders={\"series\": NaNLabelEncoder().fit(data.series)},\n",
    "    group_ids=[\"series\"],\n",
    "    # only unknown variable is \"value\" - and N-Beats can also not take any additional variables\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    max_encoder_length=context_length,\n",
    "    max_prediction_length=prediction_length,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx=training_cutoff + 1)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "from transformers import AutoTokenizer, AutoformerForPrediction, AutoformerConfig,AutoformerPreTrainedModel\n",
    "import torch\n",
    "import electricity.elec_nbeats.nbeats as nbeats\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "elec = pd.read_csv(\"electricity/electricity.csv\",index_col=0)\n",
    "\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    Preprocessing.\n",
    "    \"\"\"\n",
    "    def __init__(self, horizon, back_horizon):\n",
    "        self.horizon = horizon\n",
    "        self.back_horizon = back_horizon\n",
    "    \n",
    "    def preprocessing(self, y, date, train_size=0.7, val_size=0.2):\n",
    "        \n",
    "        y = y.copy().astype('float')\n",
    "\n",
    "        train = y[:int(train_size*len(y))]\n",
    "        val = y[int(train_size*len(y))-self.back_horizon:int((train_size+val_size)*len(y))]\n",
    "        test = y[int((train_size+val_size)*len(y))-self.back_horizon:]\n",
    "        train_date = date[:int(train_size*len(y))]\n",
    "        val_date = date[int(train_size*len(y))-self.back_horizon:int((train_size+val_size)*len(y))]\n",
    "        test_date = date[int((train_size+val_size)*len(y))-self.back_horizon:]\n",
    "\n",
    "        # Training set\n",
    "        self.X_train, self.y_train, self.train_date = self.create_sequences(train, \n",
    "                                                                            train, \n",
    "                                                                            train_date,\n",
    "                                                                            self.horizon, \n",
    "                                                                            self.back_horizon)\n",
    "        # Validation set\n",
    "        self.X_val, self.y_val, self.val_date = self.create_sequences(val,\n",
    "                                                                      val,\n",
    "                                                                      val_date,\n",
    "                                                                      self.horizon,\n",
    "                                                                      self.back_horizon)\n",
    "        # Testing set\n",
    "        self.X_test, self.y_test, self.test_date = self.create_sequences(test,\n",
    "                                                                         test,\n",
    "                                                                         test_date,\n",
    "                                                                         self.horizon,\n",
    "                                                                         self.back_horizon)\n",
    "\n",
    "        # training on all database\n",
    "        self.X_train_all, self.y_train_all, self.train_all_date = self.create_sequences(y, \n",
    "                                                                                        y,\n",
    "                                                                                        date,\n",
    "                                                                                        self.horizon,\n",
    "                                                                                        self.back_horizon)\n",
    "            \n",
    "    @staticmethod\n",
    "    def create_sequences(X, y, d, horizon, time_steps):\n",
    "        Xs, ys, ds = [], [], []\n",
    "        for col in range(X.shape[1]):\n",
    "            for i in range(0, len(X)-time_steps-horizon, 1):\n",
    "                Xs.append(X[i:(i+time_steps), col])\n",
    "                ys.append(y[(i+time_steps):(i+time_steps+horizon), col])\n",
    "                ds.append(d[(i+time_steps):(i+time_steps+horizon)])\n",
    "\n",
    "        return np.array(Xs), np.array(ys), np.array(ds)\n",
    "    \n",
    "back_horizon = 3 * 120\n",
    "horizon = 120\n",
    "datasets = DataSet(horizon,  back_horizon)\n",
    "datasets.preprocessing(elec.values, elec.index, train_size=0.7, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  60.,   77.,   75., ...,   79.,   71.,   62.],\n",
       "       [  77.,   75.,   60., ...,   71.,   62.,   64.],\n",
       "       [  75.,   60.,   60., ...,   62.,   64.,   62.],\n",
       "       ...,\n",
       "       [2938., 2874., 2751., ..., 3755., 3609., 3413.],\n",
       "       [2874., 2751., 2682., ..., 3609., 3413., 3115.],\n",
       "       [2751., 2682., 2779., ..., 3413., 3115., 3054.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.X_train\n",
    "datasets.X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14.,   69.,  234., ..., 1558.,  182., 2162.],\n",
       "       [  18.,   92.,  312., ..., 2177.,  253., 2835.],\n",
       "       [  21.,   96.,  312., ..., 2193.,  218., 2764.],\n",
       "       ...,\n",
       "       [  12.,   93.,    8., ..., 1864.,  621., 2650.],\n",
       "       [  10.,   92.,    8., ..., 2623.,  783., 2719.],\n",
       "       [  11.,   88.,    8., ..., 2706.,  647., 2640.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.reshape(26304,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 322)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
