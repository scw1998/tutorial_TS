{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>676.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>4719.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>6617.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>96600.0</td>\n",
       "      <td>4285.0</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 05:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>6365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 06:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>807.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>91300.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2721.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     0     1      2      3      4       5     6       7  \\\n",
       "0  2016-07-01 02:00:00  14.0  69.0  234.0  415.0  215.0  1056.0  29.0   840.0   \n",
       "1  2016-07-01 03:00:00  18.0  92.0  312.0  556.0  292.0  1363.0  29.0  1102.0   \n",
       "2  2016-07-01 04:00:00  21.0  96.0  312.0  560.0  272.0  1240.0  29.0  1025.0   \n",
       "3  2016-07-01 05:00:00  20.0  92.0  312.0  443.0  213.0   845.0  24.0   833.0   \n",
       "4  2016-07-01 06:00:00  22.0  91.0  312.0  346.0  190.0   647.0  16.0   733.0   \n",
       "\n",
       "       8  ...    311    312      313     314     315   316   317     318  \\\n",
       "0  226.0  ...  676.0  372.0  80100.0  4719.0  5002.0  48.0  38.0  1558.0   \n",
       "1  271.0  ...  805.0  452.0  95200.0  4643.0  6617.0  65.0  47.0  2177.0   \n",
       "2  270.0  ...  817.0  430.0  96600.0  4285.0  6571.0  64.0  43.0  2193.0   \n",
       "3  179.0  ...  801.0  291.0  94500.0  4222.0  6365.0  65.0  39.0  1315.0   \n",
       "4  186.0  ...  807.0  279.0  91300.0  4116.0  6298.0  75.0  40.0  1378.0   \n",
       "\n",
       "     319      OT  \n",
       "0  182.0  2162.0  \n",
       "1  253.0  2835.0  \n",
       "2  218.0  2764.0  \n",
       "3  195.0  2735.0  \n",
       "4  191.0  2721.0  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"electricity.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(data.columns)\n",
    "cols.remove('date')\n",
    "data=data[['date'] + cols]\n",
    "cols_data = data.columns[1:]\n",
    "df = data[cols_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>676.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>4719.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>6617.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>96600.0</td>\n",
       "      <td>4285.0</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 05:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>6365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 06:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>807.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>91300.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2016-07-04 21:00:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>231500.0</td>\n",
       "      <td>15111.0</td>\n",
       "      <td>17025.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>3612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2016-07-04 22:00:00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>194100.0</td>\n",
       "      <td>14875.0</td>\n",
       "      <td>16683.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>3332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2016-07-04 23:00:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>184500.0</td>\n",
       "      <td>14340.0</td>\n",
       "      <td>16184.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>3436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2016-07-05 00:00:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>11209.0</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2527.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>3417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2016-07-05 01:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>174600.0</td>\n",
       "      <td>8841.0</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>3514.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date     0      1      2      3      4       5     6  \\\n",
       "0   2016-07-01 02:00:00  14.0   69.0  234.0  415.0  215.0  1056.0  29.0   \n",
       "1   2016-07-01 03:00:00  18.0   92.0  312.0  556.0  292.0  1363.0  29.0   \n",
       "2   2016-07-01 04:00:00  21.0   96.0  312.0  560.0  272.0  1240.0  29.0   \n",
       "3   2016-07-01 05:00:00  20.0   92.0  312.0  443.0  213.0   845.0  24.0   \n",
       "4   2016-07-01 06:00:00  22.0   91.0  312.0  346.0  190.0   647.0  16.0   \n",
       "..                  ...   ...    ...    ...    ...    ...     ...   ...   \n",
       "91  2016-07-04 21:00:00  41.0  126.0   16.0  940.0  409.0  1547.0  28.0   \n",
       "92  2016-07-04 22:00:00  27.0  136.0   20.0  906.0  349.0  1614.0  32.0   \n",
       "93  2016-07-04 23:00:00  63.0  120.0  121.0  832.0  368.0  1351.0  23.0   \n",
       "94  2016-07-05 00:00:00  55.0  109.0  332.0  727.0  401.0  1339.0  21.0   \n",
       "95  2016-07-05 01:00:00  46.0   98.0  327.0  608.0  358.0  1189.0  18.0   \n",
       "\n",
       "         7      8  ...     311     312       313      314      315    316  \\\n",
       "0    840.0  226.0  ...   676.0   372.0   80100.0   4719.0   5002.0   48.0   \n",
       "1   1102.0  271.0  ...   805.0   452.0   95200.0   4643.0   6617.0   65.0   \n",
       "2   1025.0  270.0  ...   817.0   430.0   96600.0   4285.0   6571.0   64.0   \n",
       "3    833.0  179.0  ...   801.0   291.0   94500.0   4222.0   6365.0   65.0   \n",
       "4    733.0  186.0  ...   807.0   279.0   91300.0   4116.0   6298.0   75.0   \n",
       "..     ...    ...  ...     ...     ...       ...      ...      ...    ...   \n",
       "91  1837.0  434.0  ...  3663.0  1936.0  231500.0  15111.0  17025.0  515.0   \n",
       "92  1595.0  405.0  ...  3629.0  1941.0  194100.0  14875.0  16683.0  513.0   \n",
       "93  1487.0  366.0  ...  3702.0  1938.0  184500.0  14340.0  16184.0  512.0   \n",
       "94  1403.0  322.0  ...  3245.0  1691.0  192000.0  11209.0  11138.0  504.0   \n",
       "95  1187.0  297.0  ...  1997.0   703.0  174600.0   8841.0   8752.0  229.0   \n",
       "\n",
       "      317     318    319      OT  \n",
       "0    38.0  1558.0  182.0  2162.0  \n",
       "1    47.0  2177.0  253.0  2835.0  \n",
       "2    43.0  2193.0  218.0  2764.0  \n",
       "3    39.0  1315.0  195.0  2735.0  \n",
       "4    40.0  1378.0  191.0  2721.0  \n",
       "..    ...     ...    ...     ...  \n",
       "91  157.0  1747.0  955.0  3612.0  \n",
       "92  134.0  1755.0  896.0  3332.0  \n",
       "93   86.0  2300.0  838.0  3436.0  \n",
       "94  148.0  2527.0  790.0  3417.0  \n",
       "95  162.0  2561.0  714.0  3514.0  \n",
       "\n",
       "[96 rows x 322 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0,     1,     2,  ...,    97,    98,    99],\n",
       "         [  100,   101,   102,  ...,   197,   198,   199],\n",
       "         [  200,   201,   202,  ...,   297,   298,   299],\n",
       "         ...,\n",
       "         [  700,   701,   702,  ...,   797,   798,   799],\n",
       "         [  800,   801,   802,  ...,   897,   898,   899],\n",
       "         [  900,   901,   902,  ...,   997,   998,   999]],\n",
       "\n",
       "        [[ 1000,  1001,  1002,  ...,  1097,  1098,  1099],\n",
       "         [ 1100,  1101,  1102,  ...,  1197,  1198,  1199],\n",
       "         [ 1200,  1201,  1202,  ...,  1297,  1298,  1299],\n",
       "         ...,\n",
       "         [ 1700,  1701,  1702,  ...,  1797,  1798,  1799],\n",
       "         [ 1800,  1801,  1802,  ...,  1897,  1898,  1899],\n",
       "         [ 1900,  1901,  1902,  ...,  1997,  1998,  1999]],\n",
       "\n",
       "        [[ 2000,  2001,  2002,  ...,  2097,  2098,  2099],\n",
       "         [ 2100,  2101,  2102,  ...,  2197,  2198,  2199],\n",
       "         [ 2200,  2201,  2202,  ...,  2297,  2298,  2299],\n",
       "         ...,\n",
       "         [ 2700,  2701,  2702,  ...,  2797,  2798,  2799],\n",
       "         [ 2800,  2801,  2802,  ...,  2897,  2898,  2899],\n",
       "         [ 2900,  2901,  2902,  ...,  2997,  2998,  2999]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[97000, 97001, 97002,  ..., 97097, 97098, 97099],\n",
       "         [97100, 97101, 97102,  ..., 97197, 97198, 97199],\n",
       "         [97200, 97201, 97202,  ..., 97297, 97298, 97299],\n",
       "         ...,\n",
       "         [97700, 97701, 97702,  ..., 97797, 97798, 97799],\n",
       "         [97800, 97801, 97802,  ..., 97897, 97898, 97899],\n",
       "         [97900, 97901, 97902,  ..., 97997, 97998, 97999]],\n",
       "\n",
       "        [[98000, 98001, 98002,  ..., 98097, 98098, 98099],\n",
       "         [98100, 98101, 98102,  ..., 98197, 98198, 98199],\n",
       "         [98200, 98201, 98202,  ..., 98297, 98298, 98299],\n",
       "         ...,\n",
       "         [98700, 98701, 98702,  ..., 98797, 98798, 98799],\n",
       "         [98800, 98801, 98802,  ..., 98897, 98898, 98899],\n",
       "         [98900, 98901, 98902,  ..., 98997, 98998, 98999]],\n",
       "\n",
       "        [[99000, 99001, 99002,  ..., 99097, 99098, 99099],\n",
       "         [99100, 99101, 99102,  ..., 99197, 99198, 99199],\n",
       "         [99200, 99201, 99202,  ..., 99297, 99298, 99299],\n",
       "         ...,\n",
       "         [99700, 99701, 99702,  ..., 99797, 99798, 99799],\n",
       "         [99800, 99801, 99802,  ..., 99897, 99898, 99899],\n",
       "         [99900, 99901, 99902,  ..., 99997, 99998, 99999]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "torch.arange(100000).view(100,10,100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import pickle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ë ¥ ì‚¬ìš©ëŸ‰: ê³ ë ¤ì‚¬í•­ ê³„ì ˆ, ì‹œê°„, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoformerForPrediction, AutoformerConfig,AutoformerPreTrainedModel\n",
    "import torch\n",
    "\n",
    "config = AutoformerConfig.from_pretrained(\"elisim/autoformer-electricity-50-epochs_\")\n",
    "model = AutoformerForPrediction(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = config.context_length\n",
    "prediction_length = config.prediction_length\n",
    "num_time_features = config.num_time_features\n",
    "num_static_categorical_features = config.num_static_categorical_features\n",
    "num_static_real_features = config.num_static_real_features\n",
    "lag_seq = config.lags_sequence\n",
    "seq_len=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=AutoformerPreTrainedModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerPreTrainedModel()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"electricity.csv\",index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "target_col_idx = df.columns.get_loc('OT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elec.head()\n",
    "input_len = 96\n",
    "X_train=df.iloc[:96,:-1]\n",
    "y_train=df.iloc[96:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_time_features(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['day_of_month'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    return df\n",
    "\n",
    "data = create_time_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data[\"OT\"]\n",
    "data=data.drop(\"OT\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.400e+01 6.900e+01 2.340e+02 ... 1.000e+00 7.000e+00 2.016e+03]\n",
      " [1.800e+01 9.200e+01 3.120e+02 ... 1.000e+00 7.000e+00 2.016e+03]\n",
      " [2.100e+01 9.600e+01 3.120e+02 ... 1.000e+00 7.000e+00 2.016e+03]\n",
      " ...\n",
      " [1.200e+01 9.300e+01 8.000e+00 ... 1.000e+00 7.000e+00 2.019e+03]\n",
      " [1.000e+01 9.200e+01 8.000e+00 ... 2.000e+00 7.000e+00 2.019e+03]\n",
      " [1.100e+01 8.800e+01 8.000e+00 ... 2.000e+00 7.000e+00 2.019e+03]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoformerConfig, AutoformerForPrediction, Trainer, TrainingArguments\n",
    "\n",
    "print(df.values)\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, input_length, prediction_length):\n",
    "        self.data = data\n",
    "        self.input_length = input_length\n",
    "        self.prediction_length = prediction_length\n",
    "        #  self.target_col_idx = target_col_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.input_length - self.prediction_length \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx + self.input_length]\n",
    "        y = self.data[idx + self.input_length:idx + self.input_length + self.prediction_length]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "# Parameters\n",
    "input_length = 96\n",
    "prediction_lengths = [96, 192, 336, 720]\n",
    "\n",
    "datasets = {pl: TimeSeriesDataset(data, input_length, pl) for pl in prediction_lengths}\n",
    "dataloaders = {pl: DataLoader(datasets[pl], batch_size=32, shuffle=True) for pl in prediction_lengths}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoformerForPrediction, AutoformerConfig,AutoformerPreTrainedModel\n",
    "import torch\n",
    "\n",
    "config = AutoformerConfig.from_pretrained(\"elisim/autoformer-electricity-50-epochs_\")\n",
    "model = AutoformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader for key 96:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataLoader for key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# Iterate through the dataloader and print the first batch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for key, dataloader in dataloaders.items():\n",
    "    print(f\"DataLoader for key {key}:\")\n",
    "    # Iterate through the dataloader and print the first batch\n",
    "    for x,y in dataloader:\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 320])\n",
      "torch.Size([32, 96, 5])\n",
      "torch.Size([32, 96, 320])\n",
      "torch.Size([32, 96, 5])\n"
     ]
    }
   ],
   "source": [
    "for past_values, past_time_features, future_values,future_time_features in dataloader:\n",
    "    print(past_values.shape)\n",
    "    print(past_time_features.shape)\n",
    "    print(future_values.shape)\n",
    "    print(future_time_features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for prediction length: 96\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m config\u001b[39m.\u001b[39mprediction_length \u001b[39m=\u001b[39m pl\n\u001b[1;32m     29\u001b[0m model \u001b[39m=\u001b[39m AutoformerForPrediction(config)\n\u001b[0;32m---> 30\u001b[0m train_model(model, dataloader)\n",
      "Cell \u001b[0;32mIn[102], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mfor\u001b[39;00m x, past_time_features, y,future_time_features \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     12\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m         outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m     14\u001b[0m             past_values\u001b[39m=\u001b[39mx,\n\u001b[1;32m     15\u001b[0m             past_time_features\u001b[39m=\u001b[39mpast_time_features,\n\u001b[1;32m     16\u001b[0m             past_observed_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m             future_values\u001b[39m=\u001b[39my\n\u001b[1;32m     18\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[101], line 21\u001b[0m, in \u001b[0;36mTimeSeriesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx:idx \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_length]\n\u001b[1;32m     20\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_length:idx \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_length \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_length]\n\u001b[0;32m---> 21\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mtensor(x, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32), torch\u001b[39m.\u001b[39mtensor(y, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(model, dataloader, num_epochs=10):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for x, past_time_features, y,future_time_features in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                past_values=x,\n",
    "                past_time_features=past_time_features,\n",
    "                past_observed_mask=None,\n",
    "                future_values=y\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Training with different prediction lengths\n",
    "for pl, dataloader in dataloaders.items():\n",
    "    print(f\"Training for prediction length: {pl}\")\n",
    "    config.prediction_length = pl\n",
    "    model = AutoformerForPrediction(config)\n",
    "    train_model(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 02:00:00</th>\n",
       "      <td>14.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>4719.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 03:00:00</th>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>6617.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 04:00:00</th>\n",
       "      <td>21.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>96600.0</td>\n",
       "      <td>4285.0</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 05:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>6365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 06:00:00</th>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>267.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>91300.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04 21:00:00</th>\n",
       "      <td>41.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>231500.0</td>\n",
       "      <td>15111.0</td>\n",
       "      <td>17025.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04 22:00:00</th>\n",
       "      <td>27.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>648.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>194100.0</td>\n",
       "      <td>14875.0</td>\n",
       "      <td>16683.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04 23:00:00</th>\n",
       "      <td>63.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>...</td>\n",
       "      <td>490.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>184500.0</td>\n",
       "      <td>14340.0</td>\n",
       "      <td>16184.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05 00:00:00</th>\n",
       "      <td>55.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>11209.0</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2527.0</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05 01:00:00</th>\n",
       "      <td>46.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>174600.0</td>\n",
       "      <td>8841.0</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0      1      2      3      4       5     6       7  \\\n",
       "date                                                                          \n",
       "2016-07-01 02:00:00  14.0   69.0  234.0  415.0  215.0  1056.0  29.0   840.0   \n",
       "2016-07-01 03:00:00  18.0   92.0  312.0  556.0  292.0  1363.0  29.0  1102.0   \n",
       "2016-07-01 04:00:00  21.0   96.0  312.0  560.0  272.0  1240.0  29.0  1025.0   \n",
       "2016-07-01 05:00:00  20.0   92.0  312.0  443.0  213.0   845.0  24.0   833.0   \n",
       "2016-07-01 06:00:00  22.0   91.0  312.0  346.0  190.0   647.0  16.0   733.0   \n",
       "...                   ...    ...    ...    ...    ...     ...   ...     ...   \n",
       "2016-07-04 21:00:00  41.0  126.0   16.0  940.0  409.0  1547.0  28.0  1837.0   \n",
       "2016-07-04 22:00:00  27.0  136.0   20.0  906.0  349.0  1614.0  32.0  1595.0   \n",
       "2016-07-04 23:00:00  63.0  120.0  121.0  832.0  368.0  1351.0  23.0  1487.0   \n",
       "2016-07-05 00:00:00  55.0  109.0  332.0  727.0  401.0  1339.0  21.0  1403.0   \n",
       "2016-07-05 01:00:00  46.0   98.0  327.0  608.0  358.0  1189.0  18.0  1187.0   \n",
       "\n",
       "                         8      9  ...     310     311     312       313  \\\n",
       "date                               ...                                     \n",
       "2016-07-01 02:00:00  226.0  265.0  ...   199.0   676.0   372.0   80100.0   \n",
       "2016-07-01 03:00:00  271.0  340.0  ...   265.0   805.0   452.0   95200.0   \n",
       "2016-07-01 04:00:00  270.0  300.0  ...   278.0   817.0   430.0   96600.0   \n",
       "2016-07-01 05:00:00  179.0  211.0  ...   271.0   801.0   291.0   94500.0   \n",
       "2016-07-01 06:00:00  186.0  179.0  ...   267.0   807.0   279.0   91300.0   \n",
       "...                    ...    ...  ...     ...     ...     ...       ...   \n",
       "2016-07-04 21:00:00  434.0  336.0  ...  1034.0  3663.0  1936.0  231500.0   \n",
       "2016-07-04 22:00:00  405.0  338.0  ...   648.0  3629.0  1941.0  194100.0   \n",
       "2016-07-04 23:00:00  366.0  319.0  ...   490.0  3702.0  1938.0  184500.0   \n",
       "2016-07-05 00:00:00  322.0  311.0  ...   361.0  3245.0  1691.0  192000.0   \n",
       "2016-07-05 01:00:00  297.0  275.0  ...   305.0  1997.0   703.0  174600.0   \n",
       "\n",
       "                         314      315    316    317     318    319  \n",
       "date                                                                \n",
       "2016-07-01 02:00:00   4719.0   5002.0   48.0   38.0  1558.0  182.0  \n",
       "2016-07-01 03:00:00   4643.0   6617.0   65.0   47.0  2177.0  253.0  \n",
       "2016-07-01 04:00:00   4285.0   6571.0   64.0   43.0  2193.0  218.0  \n",
       "2016-07-01 05:00:00   4222.0   6365.0   65.0   39.0  1315.0  195.0  \n",
       "2016-07-01 06:00:00   4116.0   6298.0   75.0   40.0  1378.0  191.0  \n",
       "...                      ...      ...    ...    ...     ...    ...  \n",
       "2016-07-04 21:00:00  15111.0  17025.0  515.0  157.0  1747.0  955.0  \n",
       "2016-07-04 22:00:00  14875.0  16683.0  513.0  134.0  1755.0  896.0  \n",
       "2016-07-04 23:00:00  14340.0  16184.0  512.0   86.0  2300.0  838.0  \n",
       "2016-07-05 00:00:00  11209.0  11138.0  504.0  148.0  2527.0  790.0  \n",
       "2016-07-05 01:00:00   8841.0   8752.0  229.0  162.0  2561.0  714.0  \n",
       "\n",
       "[96 rows x 320 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy.abc import y\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.context_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 327)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 327)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec = pd.read_csv(\"electricity.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | date                |   0 |   1 |   2 |   3 |   4 |    5 |   6 |    7 |   8 |   9 |   10 |   11 |   12 |   13 |   14 |   15 |   16 |   17 |   18 |   19 |   20 |   21 |   22 |   23 |   24 |   25 |   26 |   27 |   28 |   29 |   30 |   31 |   32 |   33 |   34 |   35 |   36 |   37 |   38 |   39 |   40 |   41 |   42 |   43 |   44 |   45 |   46 |   47 |   48 |   49 |   50 |   51 |   52 |   53 |   54 |   55 |   56 |   57 |   58 |   59 |   60 |   61 |   62 |   63 |   64 |   65 |   66 |   67 |   68 |   69 |   70 |   71 |   72 |   73 |   74 |   75 |   76 |   77 |   78 |   79 |   80 |   81 |   82 |   83 |   84 |   85 |   86 |   87 |   88 |   89 |   90 |   91 |   92 |   93 |   94 |   95 |   96 |   97 |   98 |   99 |   100 |   101 |   102 |   103 |   104 |   105 |   106 |   107 |   108 |   109 |   110 |   111 |   112 |   113 |   114 |   115 |   116 |   117 |   118 |   119 |   120 |   121 |   122 |   123 |   124 |   125 |   126 |   127 |   128 |   129 |   130 |   131 |   132 |   133 |   134 |   135 |   136 |   137 |   138 |   139 |   140 |   141 |   142 |   143 |   144 |   145 |   146 |   147 |   148 |   149 |   150 |   151 |   152 |   153 |   154 |   155 |   156 |   157 |   158 |   159 |   160 |   161 |   162 |   163 |   164 |   165 |   166 |   167 |   168 |   169 |   170 |   171 |   172 |   173 |   174 |   175 |   176 |   177 |   178 |   179 |   180 |   181 |   182 |   183 |   184 |   185 |   186 |   187 |   188 |   189 |   190 |   191 |   192 |   193 |   194 |   195 |   196 |   197 |   198 |   199 |   200 |   201 |   202 |   203 |   204 |   205 |   206 |   207 |   208 |   209 |   210 |   211 |   212 |   213 |   214 |   215 |   216 |   217 |   218 |   219 |   220 |   221 |   222 |   223 |   224 |   225 |   226 |   227 |   228 |   229 |   230 |   231 |   232 |   233 |   234 |   235 |   236 |   237 |   238 |   239 |   240 |   241 |   242 |   243 |   244 |   245 |   246 |   247 |   248 |   249 |   250 |   251 |   252 |   253 |   254 |   255 |   256 |   257 |   258 |   259 |   260 |   261 |   262 |   263 |   264 |   265 |   266 |   267 |   268 |   269 |   270 |   271 |   272 |   273 |   274 |   275 |   276 |   277 |   278 |   279 |   280 |   281 |   282 |   283 |   284 |   285 |   286 |   287 |   288 |   289 |   290 |   291 |   292 |   293 |   294 |   295 |   296 |   297 |   298 |   299 |   300 |   301 |   302 |   303 |   304 |   305 |   306 |   307 |   308 |   309 |   310 |   311 |   312 |   313 |   314 |   315 |   316 |   317 |   318 |   319 |   OT |\n",
      "|---:|:--------------------|----:|----:|----:|----:|----:|-----:|----:|-----:|----:|----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|-----:|\n",
      "|  0 | 2016-07-01 02:00:00 |  14 |  69 | 234 | 415 | 215 | 1056 |  29 |  840 | 226 | 265 |  179 |  148 |  112 |  171 |  229 | 1001 |   49 |  162 |  594 |   88 |   34 |  885 |  122 |  102 |  425 |  185 |  360 |   83 |  449 |   37 |  408 |  346 |  521 |  177 | 4047 |  151 |  218 |  811 |  112 |   68 | 4131 |  784 |  184 |  167 |  325 |  278 |  224 |  158 |  127 |  512 |  502 |  126 |  407 |  293 |  137 | 3976 |  280 |  267 |  681 |  673 |  837 |  215 |  192 |  397 |  119 |  453 |  289 |  290 |  124 |  243 |  132 |   78 |  440 |  158 |  380 |  795 |  598 | 1834 |  436 |  405 | 1089 |   52 |  358 |    9 |   30 |   13 |   28 |  295 |  658 |  880 |   38 |  750 | 1768 |  747 |  602 |  167 |  528 |  333 |  522 |  191 |   439 |    27 |    69 |   455 |   403 |   385 |  1420 |   158 |    63 |   428 |   119 |   174 |  1454 |   612 |    20 |    51 |   504 |   252 |     0 |  7952 |  1013 |    78 |   106 |   221 |   417 |   103 |   424 |   263 |  2788 |    76 |   105 |  7367 |  1457 |  7097 |   816 |  2465 |   258 |    92 |   694 |   333 |   397 |   358 |   181 |   304 |   121 |   181 |     9 |    80 |   847 |   920 |  3404 |  1143 |   692 |  7006 |   902 | 35376 |   322 |   443 |  1071 |  1455 |   582 |   713 |   973 |  1934 |  1057 |   321 |  1423 | 14800 |  1111 |  1861 |   351 |   653 |  2992 |   771 |   692 |  4423 |   389 |  2624 |   781 |  5040 |   286 |  1690 |  1918 |   644 |  1221 |   589 | 11003 |  2236 |   222 |  1276 |   163 |   325 |   178 |  1634 |   358 |   185 |  1090 |   246 |   689 |  7162 |   430 |   267 |   301 |   455 |  1474 |   782 |   300 |   187 |   177 |   200 |   461 |   570 |   534 |   295 |   367 |   245 |   450 |   535 |   133 |   592 |   335 |   362 |   507 |   546 |   138 |   468 |  1906 |   127 |   358 |   332 |  1090 |   720 |   297 |  3859 |   220 |   170 | 29272 |   525 |   293 |   253 |   772 |   141 |   199 |   212 |   351 |   139 |  1156 |   228 |   218 |   197 |  1439 |   655 |   207 |   315 |  3021 |  1336 |   344 |   274 |   300 |   339 |   136 |   149 |  1359 |   479 |  1479 |   289 |   719 |   448 |  2907 |   222 |   653 |   981 |   363 |   203 |   209 |   213 |  3199 |   720 |   552 |   640 |  1062 |  2787 |   511 |   159 |   675 |   116 |    76 |   110 |   451 |   292 |  4770 |   123 |  1623 |   234 |   139 |   296 |  2412 |   317 |    16 |   164 |   241 |   575 |  1824 |    89 |   820 |    66 |   847 |    81 |  2002 |   937 |   199 |   676 |   372 | 80100 |  4719 |  5002 |    48 |    38 |  1558 |   182 | 2162 |\n",
      "|  1 | 2016-07-01 03:00:00 |  18 |  92 | 312 | 556 | 292 | 1363 |  29 | 1102 | 271 | 340 |  235 |  192 |  143 |  213 |  301 | 1223 |   64 |  216 |  758 |  126 |   39 | 1074 |  150 |  127 |  585 |  219 |  451 |  108 |  606 |   60 |  548 |  470 |  632 |  224 | 4684 |  190 |  260 |  950 |  138 |   89 | 5024 |  992 |  241 |  231 |  438 |  360 |  257 |  202 |  160 |  635 |  779 |  147 |  527 |  373 |  164 | 5053 |  329 |  362 |  900 |  833 | 1035 |  282 |  236 |  512 |  151 |  560 |  351 |  394 |  165 |  296 |  170 |   98 |  529 |  198 |  435 |  964 |  740 | 2211 |  539 |  499 | 1451 |   44 |  616 |   10 |   39 |   17 |   39 |  398 |  822 |  943 |   53 |  786 | 3654 |  997 |  744 |  221 |  701 |  472 |  680 |  244 |   494 |    31 |    96 |   608 |   544 |   330 |   440 |   126 |    75 |   575 |   145 |   223 |  1989 |   784 |    29 |    68 |   656 |   332 |     0 | 10547 |  1359 |   103 |   140 |   285 |   565 |   136 |   551 |   262 |  3353 |    69 |   108 |  7221 |  1443 |  7474 |   825 |  2333 |   255 |    87 |   700 |   329 |   397 |   369 |   192 |   283 |   126 |   180 |    10 |    84 |   795 |   920 |  3290 |   945 |   666 |  7145 |   861 | 37169 |   330 |   398 |   969 |  1267 |   603 |   660 |   919 |  1721 |  1057 |   329 |  1411 | 14203 |  1120 |  1602 |   357 |   660 |  2856 |   763 |   703 |  4334 |   406 |  2516 |   660 |  5091 |   277 |  1705 |  1756 |   614 |  1185 |   462 |  9792 |  2113 |   216 |  1282 |   165 |   325 |   163 |  1601 |   335 |   203 |  1075 |   246 |   733 |  7150 |   395 |   287 |   294 |   455 |  1532 |   792 |   303 |   143 |   188 |   167 |   449 |   560 |   530 |   291 |   357 |   246 |   418 |   538 |   131 |   588 |   332 |   369 |   511 |   534 |   130 |   460 |  1821 |   124 |   334 |   340 |  1042 |   665 |   293 |  3958 |   204 |   167 | 27689 |   496 |   266 |   226 |   682 |   135 |   189 |   215 |   337 |   132 |  1100 |   226 |    12 |   182 |  1418 |   664 |   212 |   311 |  2445 |  1170 |   338 |   264 |   280 |   324 |   142 |   141 |  1292 |   487 |  1308 |   274 |   711 |   446 |  2772 |   199 |   553 |   975 |   364 |   189 |   203 |   217 |  3078 |   706 |   547 |   610 |  1048 |  2647 |   517 |   164 |   667 |   128 |    85 |   101 |   606 |   374 |  4189 |   149 |  2065 |   318 |   125 |   334 |  3166 |   385 |    32 |   123 |   318 |   750 |  2418 |   104 |  1268 |    87 |   988 |    91 |  2685 |   866 |   265 |   805 |   452 | 95200 |  4643 |  6617 |    65 |    47 |  2177 |   253 | 2835 |\n",
      "|  2 | 2016-07-01 04:00:00 |  21 |  96 | 312 | 560 | 272 | 1240 |  29 | 1025 | 270 | 300 |  221 |  171 |  132 |  185 |  261 | 1172 |   61 |  197 |  736 |  115 |   38 |  936 |  149 |  117 |  551 |  193 |  433 |  102 |  616 |   53 |  472 |  452 |  551 |  213 | 4297 |  166 |  259 |  861 |  129 |   90 | 4611 |  945 |  238 |  205 |  423 |  326 |  242 |  195 |  150 |  614 |  727 |  133 |  513 |  338 |  144 | 4822 |  390 |  332 |  908 |  851 |  924 |  243 |  224 |  487 |  138 |  509 |  323 |  383 |  158 |  260 |  164 |   89 |  498 |  191 |  397 |  908 |  642 | 2254 |  559 |  518 | 1338 |   40 |  598 |   12 |   36 |   17 |   37 |  404 |  729 |  868 |   48 |  784 | 3142 | 1008 |  747 |  224 |  704 |  479 |  699 |  245 |   461 |    32 |    98 |   597 |   528 |   550 |   262 |   126 |    56 |   578 |   162 |   227 |  1891 |   802 |    29 |    68 |   673 |   337 |     0 | 10587 |  1365 |   102 |   139 |   276 |   563 |   137 |   452 |   261 |  3853 |    67 |   111 |  7055 |   788 |  7670 |   345 |  2421 |   261 |    90 |   661 |   299 |   369 |   342 |   186 |   269 |   125 |   183 |    10 |    82 |   769 |   939 |  3254 |   927 |   707 |  6939 |   840 | 36668 |   341 |   382 |   937 |  1172 |   609 |   613 |   909 |  1700 |  1032 |   324 |  1394 | 13952 |  1056 |  1488 |   318 |   646 |  2911 |   742 |   707 |  4417 |   364 |  2521 |   686 |  4913 |   270 |  1755 |  1646 |   600 |  1219 |   464 | 10422 |  2072 |   205 |  1291 |   150 |   334 |   153 |  1497 |   312 |   186 |  1100 |   231 |   718 |  6842 |   399 |   269 |   287 |   443 |  1531 |   761 |   302 |   141 |   182 |   167 |   439 |   556 |   544 |   297 |   382 |   234 |   388 |   572 |   129 |   601 |   329 |   357 |   450 |   520 |   140 |   430 |  1666 |   127 |   322 |   329 |  1018 |   653 |   293 |  3770 |   201 |   162 | 27938 |   512 |   241 |   211 |   670 |   138 |   201 |   202 |   330 |   136 |  1100 |   231 |    12 |   179 |  1364 |   637 |   212 |   328 |  2267 |  1134 |   336 |   262 |   275 |   322 |   129 |   136 |  1317 |   486 |  1398 |   271 |   721 |   431 |  2734 |   183 |   546 |   966 |   371 |   177 |   191 |   217 |  2967 |   642 |   532 |   613 |  1014 |  2535 |   489 |   161 |   649 |   148 |    82 |    84 |   613 |   369 |  4041 |   112 |  1987 |   305 |   123 |   238 |  3194 |   384 |    32 |   123 |   294 |   725 |  2380 |   120 |  1254 |    88 |   942 |    77 |  2661 |   839 |   278 |   817 |   430 | 96600 |  4285 |  6571 |    64 |    43 |  2193 |   218 | 2764 |\n",
      "|  3 | 2016-07-01 05:00:00 |  20 |  92 | 312 | 443 | 213 |  845 |  24 |  833 | 179 | 211 |  170 |  149 |  116 |  151 |  209 |  813 |   40 |  173 |  661 |   93 |   21 |  833 |  114 |   86 |  434 |  145 |  351 |   78 |  449 |   54 |  375 |  410 |  491 |  170 | 3252 |  114 |  180 |  685 |  128 |   69 | 3470 |  764 |  224 |  160 |  317 |  268 |  173 |  178 |   79 |  544 |  630 |  121 |  466 |  314 |   94 | 3643 |  231 |  263 |  669 |  696 |  653 |  181 |  182 |  383 |  136 |  400 |  199 |  326 |  117 |  208 |  142 |   62 |  382 |  160 |  280 |  731 |  489 | 1791 |  410 |  464 | 1048 |   40 |  526 |   12 |   44 |   18 |   45 |  411 |  697 |  872 |   48 |  727 |  949 | 1002 |  687 |  222 |  707 |  601 |  667 |  246 |   409 |    29 |    91 |   603 |   553 |   385 |   232 |   126 |    74 |   578 |   160 |   235 |  1818 |   802 |    30 |    66 |   651 |   331 |     0 | 10524 |  1348 |   103 |   143 |   274 |   564 |   137 |   449 |   262 |  3492 |    69 |   104 |  7171 |   704 |  7595 |   240 |  2399 |   267 |    88 |   649 |   314 |   364 |   345 |   178 |   258 |   131 |   186 |    10 |    83 |   781 |   890 |  3239 |   945 |   703 |  7048 |   845 | 36293 |   335 |   380 |   950 |  1179 |   592 |   608 |   934 |  1651 |  1006 |   333 |  1365 | 14112 |  1017 |  1462 |   340 |   608 |  3039 |   716 |   718 |  4391 |   353 |  2456 |   697 |  4571 |   284 |  1582 |  1609 |   636 |  1186 |   486 | 10529 |  2128 |   210 |  1300 |   154 |   314 |   157 |  1487 |   298 |   181 |  1107 |   237 |   741 |  6990 |   395 |   285 |   312 |   437 |  1470 |   749 |   295 |   143 |   180 |   155 |   427 |   549 |   552 |   286 |   377 |   226 |   404 |   540 |   121 |   591 |   364 |   361 |   503 |   542 |   132 |   446 |  1683 |   131 |   319 |   339 |  1045 |   696 |   296 |  3790 |   194 |   163 | 26686 |   493 |   244 |   206 |   668 |   138 |   192 |   198 |   330 |   133 |  1121 |   226 |    12 |   183 |  1385 |   616 |   238 |   323 |  2181 |  1141 |   330 |   258 |   265 |   320 |   133 |   139 |  1301 |   463 |  1515 |   266 |   729 |   419 |  2637 |   184 |   534 |   930 |   371 |   170 |   188 |   209 |  2907 |   696 |   517 |   601 |   987 |  2350 |   511 |   166 |   661 |   155 |    76 |    87 |   621 |   369 |  4031 |   115 |  1970 |   305 |   207 |   211 |  3075 |   384 |    24 |   164 |   279 |   725 |  2375 |   119 |  1246 |    87 |   867 |   102 |  2684 |   838 |   271 |   801 |   291 | 94500 |  4222 |  6365 |    65 |    39 |  1315 |   195 | 2735 |\n",
      "|  4 | 2016-07-01 06:00:00 |  22 |  91 | 312 | 346 | 190 |  647 |  16 |  733 | 186 | 179 |  142 |  170 |   99 |  136 |  148 |  688 |   29 |  144 |  619 |   86 |   20 |  815 |   80 |   73 |  304 |  118 |  289 |   75 |  347 |   44 |  288 |  377 |  479 |  148 | 2639 |   86 |  141 |  623 |  115 |   54 | 2774 |  626 |  167 |  145 |  232 |  220 |  141 |  151 |   47 |  487 |  569 |  106 |  345 |  289 |   73 | 2669 |  146 |  229 |  528 |  538 |  584 |  144 |  155 |  323 |  127 |  322 |  166 |  277 |   98 |  187 |  122 |   55 |  336 |  147 |  233 |  574 |  393 | 1539 |  296 |  407 |  833 |   40 |  488 |   12 |   46 |   19 |   35 |  409 |  696 |  831 |   47 |  709 |  891 |  997 |  680 |  223 |  713 |  455 |  493 |  242 |   424 |    32 |   106 |   598 |   543 |   605 |   222 |   126 |    59 |   323 |   154 |   226 |  1701 |   778 |    29 |    64 |   639 |   337 |     0 | 10525 |  1352 |   105 |   144 |   271 |   567 |   137 |   444 |   261 |  3712 |    68 |   106 |  7153 |   678 |  7426 |   237 |  2300 |   258 |    79 |   652 |   299 |   350 |   343 |   184 |   272 |   125 |   186 |    11 |    86 |   718 |   914 |  3219 |   984 |   684 |  7061 |   808 | 37334 |   337 |   385 |   935 |  1143 |   595 |   489 |   951 |  1466 |   973 |   303 |  1394 | 13968 |  1009 |  1473 |   299 |   615 |  3394 |   852 |   688 |  4205 |   356 |  2439 |   673 |  4812 |   272 |  1613 |  1645 |   642 |  1212 |   652 | 10371 |  2056 |   230 |  1286 |   147 |   317 |   184 |  1644 |   302 |   191 |  1067 |   235 |   679 |  6853 |   414 |   286 |   294 |   452 |  1495 |   758 |   298 |   131 |   190 |   162 |   451 |   554 |   514 |   283 |   376 |   237 |   398 |   552 |   121 |   578 |   338 |   348 |   475 |   543 |   130 |   442 |  1746 |   127 |   328 |   355 |   985 |   672 |   290 |  3831 |   196 |   170 | 25519 |   485 |   261 |   207 |   660 |   135 |   189 |   200 |   340 |   143 |  1072 |   222 |    12 |   189 |  1396 |   601 |   233 |   338 |  2091 |  1157 |   335 |   280 |   273 |   327 |   130 |   138 |  1333 |   502 |  1537 |   272 |   721 |   419 |  2665 |   185 |   600 |   942 |   349 |   178 |   190 |   215 |  3163 |   673 |   518 |   591 |   953 |  2357 |   524 |   160 |   649 |   121 |    82 |    87 |   622 |   370 |  4056 |   111 |  1971 |   312 |   158 |   212 |  3059 |   388 |    32 |   123 |   259 |   725 |  2367 |   110 |  1212 |    86 |   819 |   103 |  2692 |   828 |   267 |   807 |   279 | 91300 |  4116 |  6298 |    75 |    40 |  1378 |   191 | 2721 |\n"
     ]
    }
   ],
   "source": [
    "h = elec.head()\n",
    "print(h.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m past_time_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((context_length, num_time_features))\n\u001b[0;32m----> 2\u001b[0m past_time_features[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m elec[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39mmonth[:context_length]\n\u001b[1;32m      3\u001b[0m past_time_features[:, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m elec[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mday[:context_length]\n\u001b[1;32m      4\u001b[0m past_time_features[:, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m elec[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mweekday[:context_length]\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/pandas/core/indexes/accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 580\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "\n",
    "past_time_features = np.zeros((context_length, num_time_features))\n",
    "past_time_features[:, 0] = elec['date'].dt.month[:context_length]\n",
    "past_time_features[:, 1] = elec['date'].dt.day[:context_length]\n",
    "past_time_features[:, 2] = elec['date'].dt.weekday[:context_length]\n",
    "past_time_features[:, 3] = elec['date'].dt.hour[:context_length]\n",
    "\n",
    "last_date = elec['date'].iloc[context_length - 1]\n",
    "future_dates = pd.date_range(start=last_date, periods=prediction_length + 1, freq='H')[1:]\n",
    "\n",
    "future_time_features = np.zeros((prediction_length, num_time_features))\n",
    "future_time_features[:, 0] = future_dates.month\n",
    "future_time_features[:, 1] = future_dates.day\n",
    "future_time_features[:, 2] = future_dates.weekday\n",
    "future_time_features[:, 3] = future_dates.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49347/1587511085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
      "/tmp/ipykernel_49347/1587511085.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
      "/tmp/ipykernel_49347/1587511085.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
      "/tmp/ipykernel_49347/1587511085.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
      "/tmp/ipykernel_49347/1587511085.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n"
     ]
    }
   ],
   "source": [
    "df_stamp = elec[['date']]\n",
    "df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "data_stamp = df_stamp.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26301</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26302</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  day  weekday  hour\n",
       "0          7    1        4     2\n",
       "1          7    1        4     3\n",
       "2          7    1        4     4\n",
       "3          7    1        4     5\n",
       "4          7    1        4     6\n",
       "...      ...  ...      ...   ...\n",
       "26299      7    1        0    21\n",
       "26300      7    1        0    22\n",
       "26301      7    1        0    23\n",
       "26302      7    2        1     0\n",
       "26303      7    2        1     1\n",
       "\n",
       "[26304 rows x 4 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stamp.iloc[:context_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec[\"date\"] = pd.to_datetime(elec[\"date\"])\n",
    "past_values = elec.iloc[:context_length, 1:].values.T  # Transpose to get shape (number of series, context_length)\n",
    "past_time_features = np.random.rand(past_values.shape[0], context_length, num_time_features)  # Random time features\n",
    "past_observed_mask = np.ones_like(past_values)\n",
    "future_values = elec.iloc[context_length:-1, 1:].values.T\n",
    "future_time_features = np.random.rand(future_values.shape[0], prediction_length, num_time_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"past_values\": torch.tensor(past_values, dtype=torch.float32),  # shape: (number of series, context_length)\n",
    "    \"past_time_features\": torch.tensor(past_time_features, dtype=torch.float32),  # shape: (number of series, context_length, num_time_features)\n",
    "    \"past_observed_mask\": torch.tensor(past_observed_mask, dtype=torch.float32),  # shape: (number of series, context_length)\n",
    "    \"future_time_features\": torch.tensor(future_time_features, dtype=torch.float32)  # shape: (number of series, prediction_length, num_time_features)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec[\"date\"] = pd.to_datetime(elec[\"date\"])\n",
    "elec[\"year\"]=elec[\"date\"].dt.year\n",
    "elec[\"month\"]=elec[\"date\"].dt.month\n",
    "elec[\"day\"]=elec[\"date\"].dt.day\n",
    "elec[\"time\"] = elec[\"date\"].dt.time\n",
    "elec[\"weekday\"] = elec[\"date\"].dt.weekday\n",
    "elec[\"minut\"] = elec[\"date\"].dt.minute\n",
    "elec = elec.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "lags cannot go further than history length, found lag 721 while history length is only 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      2\u001b[0m     past_values\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_values\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      3\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_time_features\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      4\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mfuture_time_features\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      5\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_observed_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:2076\u001b[0m, in \u001b[0;36mAutoformerForPrediction.generate\u001b[0;34m(self, past_values, past_time_features, future_time_features, past_observed_mask, static_categorical_features, static_real_features, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m   1978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m   1979\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     output_hidden_states: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1988\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleTSPredictionOutput:\n\u001b[1;32m   1989\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[39m    Greedily generate sequences of sample predictions from a model with a probability distribution head.\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[39m        multivariate predictions.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2076\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2077\u001b[0m         static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   2078\u001b[0m         static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   2079\u001b[0m         past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   2080\u001b[0m         past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   2081\u001b[0m         past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   2082\u001b[0m         future_time_features\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2083\u001b[0m         future_values\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2084\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2085\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2086\u001b[0m         return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2087\u001b[0m         use_cache\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2088\u001b[0m     )\n\u001b[1;32m   2090\u001b[0m     decoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_decoder()\n\u001b[1;32m   2091\u001b[0m     enc_last_hidden \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mencoder_last_hidden_state\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1918\u001b[0m, in \u001b[0;36mAutoformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m future_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1919\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1920\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1921\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1922\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1923\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1924\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1925\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1926\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1927\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1928\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1929\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1930\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1931\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1932\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1933\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1934\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1935\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1936\u001b[0m )\n\u001b[1;32m   1938\u001b[0m prediction_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1660\u001b[0m, in \u001b[0;36mAutoformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1657\u001b[0m use_cache \u001b[39m=\u001b[39m use_cache \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_cache\n\u001b[1;32m   1658\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1660\u001b[0m transformer_inputs, temporal_features, loc, scale, static_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_network_inputs(\n\u001b[1;32m   1661\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1662\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1663\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1664\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1665\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1666\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1667\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1668\u001b[0m )\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1671\u001b[0m     enc_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m   1672\u001b[0m         (\n\u001b[1;32m   1673\u001b[0m             transformer_inputs[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1677\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1585\u001b[0m, in \u001b[0;36mAutoformerModel.create_network_inputs\u001b[0;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[39m# lagged features\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m subsequences_length \u001b[39m=\u001b[39m (\n\u001b[1;32m   1581\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mprediction_length\n\u001b[1;32m   1582\u001b[0m     \u001b[39mif\u001b[39;00m future_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length\n\u001b[1;32m   1584\u001b[0m )\n\u001b[0;32m-> 1585\u001b[0m lagged_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_lagged_subsequences(sequence\u001b[39m=\u001b[39;49minputs, subsequences_length\u001b[39m=\u001b[39;49msubsequences_length)\n\u001b[1;32m   1586\u001b[0m lags_shape \u001b[39m=\u001b[39m lagged_sequence\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1587\u001b[0m reshaped_lagged_sequence \u001b[39m=\u001b[39m lagged_sequence\u001b[39m.\u001b[39mreshape(lags_shape[\u001b[39m0\u001b[39m], lags_shape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1480\u001b[0m, in \u001b[0;36mAutoformerModel.get_lagged_subsequences\u001b[0;34m(self, sequence, subsequences_length, shift)\u001b[0m\n\u001b[1;32m   1478\u001b[0m sequence_length \u001b[39m=\u001b[39m sequence\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mmax\u001b[39m(indices) \u001b[39m+\u001b[39m subsequences_length \u001b[39m>\u001b[39m sequence_length:\n\u001b[0;32m-> 1480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1481\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlags cannot go further than history length, found lag \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(indices)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1482\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhile history length is only \u001b[39m\u001b[39m{\u001b[39;00msequence_length\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1483\u001b[0m     )\n\u001b[1;32m   1485\u001b[0m \u001b[39m# extracts the lagged subsequences from the input sequence using the calculated indices\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m lagged_values \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: lags cannot go further than history length, found lag 721 while history length is only 48"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerEncoder(\n",
       "  (value_embedding): AutoformerValueEmbedding(\n",
       "    (value_projection): Linear(in_features=47, out_features=16, bias=False)\n",
       "  )\n",
       "  (embed_positions): AutoformerSinusoidalPositionalEmbedding(72, 16)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x AutoformerEncoderLayer(\n",
       "      (self_attn): AutoformerAttention(\n",
       "        (k_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (v_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (q_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (out_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): GELUActivation()\n",
       "      (fc1): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (final_layer_norm): AutoformerLayernorm(\n",
       "        (layernorm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decomp1): AutoformerSeriesDecompositionLayer(\n",
       "        (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "      )\n",
       "      (decomp2): AutoformerSeriesDecompositionLayer(\n",
       "        (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put = model.get_encoder()\n",
    "out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>676.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>4719.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>6617.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>96600.0</td>\n",
       "      <td>4285.0</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 05:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>6365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 06:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>807.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>91300.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2721.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     0     1      2      3      4       5     6       7  \\\n",
       "0  2016-07-01 02:00:00  14.0  69.0  234.0  415.0  215.0  1056.0  29.0   840.0   \n",
       "1  2016-07-01 03:00:00  18.0  92.0  312.0  556.0  292.0  1363.0  29.0  1102.0   \n",
       "2  2016-07-01 04:00:00  21.0  96.0  312.0  560.0  272.0  1240.0  29.0  1025.0   \n",
       "3  2016-07-01 05:00:00  20.0  92.0  312.0  443.0  213.0   845.0  24.0   833.0   \n",
       "4  2016-07-01 06:00:00  22.0  91.0  312.0  346.0  190.0   647.0  16.0   733.0   \n",
       "\n",
       "       8  ...    311    312      313     314     315   316   317     318  \\\n",
       "0  226.0  ...  676.0  372.0  80100.0  4719.0  5002.0  48.0  38.0  1558.0   \n",
       "1  271.0  ...  805.0  452.0  95200.0  4643.0  6617.0  65.0  47.0  2177.0   \n",
       "2  270.0  ...  817.0  430.0  96600.0  4285.0  6571.0  64.0  43.0  2193.0   \n",
       "3  179.0  ...  801.0  291.0  94500.0  4222.0  6365.0  65.0  39.0  1315.0   \n",
       "4  186.0  ...  807.0  279.0  91300.0  4116.0  6298.0  75.0  40.0  1378.0   \n",
       "\n",
       "     319      OT  \n",
       "0  182.0  2162.0  \n",
       "1  253.0  2835.0  \n",
       "2  218.0  2764.0  \n",
       "3  195.0  2735.0  \n",
       "4  191.0  2721.0  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec = pd.read_csv(\"electricity.csv\")\n",
    "elec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec[\"date\"] = pd.to_datetime(elec[\"date\"])\n",
    "# elec[\"year\"]=elec[\"date\"].dt.year\n",
    "# elec[\"month\"]=elec[\"date\"].dt.month\n",
    "# elec[\"day\"]=elec[\"date\"].dt.day\n",
    "# elec[\"time\"] = elec[\"date\"].dt.time\n",
    "elec = elec.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = elec[\"OT\"]\n",
    "feature = elec.drop(\"OT\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoformerForPrediction' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoformerForPrediction' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import AutoformerForPrediction\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"hf-internal-testing/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "config = AutoformerConfig(\"huggingface/autoformer-tourism-monthly\")\n",
    "model = AutoformerForPrediction.from_pretrained(\"huggingface/autoformer-tourism-monthly\")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 61])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"past_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 61, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"past_time_features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 61, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 61, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"past_time_features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "\n",
    "dataset = get_dataset(\"electricity\")\n",
    "h = get_dataset(\"electricity_hourly\")\n",
    "freq = dataset.metadata.freq\n",
    "prediction_length = dataset.metadata.prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='H', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='321')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=48)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_example = next(iter(dataset.train))\n",
    "test_example = next(iter(dataset.test))\n",
    "\n",
    "num_of_samples = 4*prediction_length\n",
    "\n",
    "figure, axes = plt.subplots()\n",
    "axes.plot(train_example[\"target\"][-num_of_samples:], color=\"blue\")\n",
    "axes.plot(\n",
    "    test_example[\"target\"][-num_of_samples - prediction_length :],\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.train\n",
    "test_dataset = dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>start</th>\n",
       "      <th>feat_static_cat</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[14.0, 18.0, 21.0, 20.0, 22.0, 20.0, 20.0, 20....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[69.0, 92.0, 96.0, 92.0, 91.0, 92.0, 91.0, 92....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[234.0, 312.0, 312.0, 312.0, 312.0, 187.0, 138...</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[415.0, 556.0, 560.0, 443.0, 346.0, 340.0, 376...</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[3]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[215.0, 292.0, 272.0, 213.0, 190.0, 178.0, 199...</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[4]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>[48.0, 65.0, 64.0, 65.0, 75.0, 64.0, 65.0, 69....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[316]</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>[38.0, 47.0, 43.0, 39.0, 40.0, 39.0, 49.0, 55....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[317]</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>[1558.0, 2177.0, 2193.0, 1315.0, 1378.0, 1250....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[318]</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>[182.0, 253.0, 218.0, 195.0, 191.0, 185.0, 191...</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[319]</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>[2162.0, 2835.0, 2764.0, 2735.0, 2721.0, 2742....</td>\n",
       "      <td>2012-01-01 00:00</td>\n",
       "      <td>[320]</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target             start  \\\n",
       "0    [14.0, 18.0, 21.0, 20.0, 22.0, 20.0, 20.0, 20....  2012-01-01 00:00   \n",
       "1    [69.0, 92.0, 96.0, 92.0, 91.0, 92.0, 91.0, 92....  2012-01-01 00:00   \n",
       "2    [234.0, 312.0, 312.0, 312.0, 312.0, 187.0, 138...  2012-01-01 00:00   \n",
       "3    [415.0, 556.0, 560.0, 443.0, 346.0, 340.0, 376...  2012-01-01 00:00   \n",
       "4    [215.0, 292.0, 272.0, 213.0, 190.0, 178.0, 199...  2012-01-01 00:00   \n",
       "..                                                 ...               ...   \n",
       "316  [48.0, 65.0, 64.0, 65.0, 75.0, 64.0, 65.0, 69....  2012-01-01 00:00   \n",
       "317  [38.0, 47.0, 43.0, 39.0, 40.0, 39.0, 49.0, 55....  2012-01-01 00:00   \n",
       "318  [1558.0, 2177.0, 2193.0, 1315.0, 1378.0, 1250....  2012-01-01 00:00   \n",
       "319  [182.0, 253.0, 218.0, 195.0, 191.0, 185.0, 191...  2012-01-01 00:00   \n",
       "320  [2162.0, 2835.0, 2764.0, 2735.0, 2721.0, 2742....  2012-01-01 00:00   \n",
       "\n",
       "    feat_static_cat  item_id  \n",
       "0               [0]        0  \n",
       "1               [1]        1  \n",
       "2               [2]        2  \n",
       "3               [3]        3  \n",
       "4               [4]        4  \n",
       "..              ...      ...  \n",
       "316           [316]      316  \n",
       "317           [317]      317  \n",
       "318           [318]      318  \n",
       "319           [319]      319  \n",
       "320           [320]      320  \n",
       "\n",
       "[321 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AsNumpyArray,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    RemoveFields,\n",
    "    SelectFields,\n",
    "    SetField,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    "    VstackFeatures,\n",
    "    RenameFields,\n",
    ")\n",
    "\n",
    "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
    "    # create a list of fields to remove later\n",
    "    remove_field_names = []\n",
    "    if config.num_static_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "    if config.num_dynamic_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "    if config.num_static_categorical_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
    "\n",
    "    return Chain(\n",
    "        # step 1: remove static/dynamic fields if not specified\n",
    "        [RemoveFields(field_names=remove_field_names)]\n",
    "        # step 2: convert the data to NumPy (potentially not needed)\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_real_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                # we expect an extra dim for the multivariate case:\n",
    "                expected_ndim=1 if config.input_size == 1 else 2,\n",
    "            ),\n",
    "            # step 3: handle the NaN's by filling in the target with zero\n",
    "            # and return the mask (which is in the observed values)\n",
    "            # true for observed values, false for nan's\n",
    "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
    "            # see loss_weights inside the xxxForPrediction model\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            # step 4: add temporal features based on freq of the dataset\n",
    "            # these serve as positional encodings\n",
    "            AddTimeFeatures(\n",
    "                start_field=FieldName.START,\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                time_features=time_features_from_frequency_str(freq),\n",
    "                pred_length=config.prediction_length,\n",
    "            ),\n",
    "            # step 5: add another temporal feature (just a single number)\n",
    "            # tells the model where in the life the value of the time series is\n",
    "            # sort of running counter\n",
    "            AddAgeFeature(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_AGE,\n",
    "                pred_length=config.prediction_length,\n",
    "                log_scale=True,\n",
    "            ),\n",
    "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                + (\n",
    "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                    if config.num_dynamic_real_features > 0\n",
    "                    else []\n",
    "                ),\n",
    "            ),\n",
    "            # step 7: rename to match HuggingFace names\n",
    "            RenameFields(\n",
    "                mapping={\n",
    "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
    "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
    "                    FieldName.FEAT_TIME: \"time_features\",\n",
    "                    FieldName.TARGET: \"values\",\n",
    "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.transform import InstanceSplitter\n",
    "from gluonts.transform.sampler import InstanceSampler\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def create_instance_splitter(\n",
    "    config: PretrainedConfig,\n",
    "    mode: str,\n",
    "    train_sampler: Optional[InstanceSampler] = None,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    ") -> Transformation:\n",
    "    assert mode in [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"train\": train_sampler\n",
    "        or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=config.prediction_length\n",
    "        ),\n",
    "        \"validation\": validation_sampler\n",
    "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=\"values\",\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=config.context_length + max(config.lags_sequence),\n",
    "        future_length=config.prediction_length,\n",
    "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from gluonts.itertools import Cyclic, Cached\n",
    "from gluonts.dataset.loader import as_stacked_batches\n",
    "\n",
    "\n",
    "def create_train_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    num_batches_per_epoch: int,\n",
    "    shuffle_buffer_length: Optional[int] = None,\n",
    "    cache_data: bool = True,\n",
    "    **kwargs,\n",
    ") -> Iterable:\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "        \"future_values\",\n",
    "        \"future_observed_mask\",\n",
    "    ]\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=True)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # we initialize a Training instance\n",
    "    instance_splitter = create_instance_splitter(config, \"train\")\n",
    "\n",
    "    # the instance splitter will sample a window of\n",
    "    # context length + lags + prediction length (from the 366 possible transformed time series)\n",
    "    # randomly from within the target time series and return an iterator.\n",
    "    stream = Cyclic(transformed_data).stream()\n",
    "    training_instances = instance_splitter.apply(stream)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        training_instances,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer_length=shuffle_buffer_length,\n",
    "        field_names=TRAINING_INPUT_NAMES,\n",
    "        output_type=torch.tensor,\n",
    "        num_batches_per_epoch=num_batches_per_epoch,\n",
    "    )\n",
    "\n",
    "def create_backtest_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data)\n",
    "\n",
    "    # we create a Validation Instance splitter which will sample the very last\n",
    "    # context window seen during training only for the encoder.\n",
    "    instance_sampler = create_instance_splitter(config, \"validation\")\n",
    "\n",
    "    # we apply the transformations in train mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )\n",
    "\n",
    "def create_test_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=False)\n",
    "\n",
    "    # We create a test Instance splitter to sample the very last\n",
    "    # context window from the dataset provided.\n",
    "    instance_sampler = create_instance_splitter(config, \"test\")\n",
    "\n",
    "    # We apply the transformations in test mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type time_series_transformer to instantiate a model of type autoformer. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoformerForPrediction, AutoformerConfig,AutoformerPreTrainedModel\n",
    "import torch\n",
    "\n",
    "config = AutoformerConfig.from_pretrained(\"scirik/time-series-transformer-electricity-load-diagrams\")\n",
    "model = AutoformerForPrediction(config)\n",
    "test_dataloader = create_backtest_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=test_dataset,\n",
    "    batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1716905971873/work/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1716905971873/work/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m forecasts_ \u001b[39m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     11\u001b[0m         static_categorical_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mstatic_categorical_features\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     12\u001b[0m         \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mnum_static_categorical_features \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m\n\u001b[1;32m     13\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m         static_real_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mstatic_real_features\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     15\u001b[0m         \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mnum_static_real_features \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m\n\u001b[1;32m     16\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m         past_time_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_time_features\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     18\u001b[0m         past_values\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_values\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     19\u001b[0m         future_time_features\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mfuture_time_features\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     20\u001b[0m         past_observed_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mpast_observed_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     forecasts_\u001b[39m.\u001b[39mappend(outputs\u001b[39m.\u001b[39msequences\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:2076\u001b[0m, in \u001b[0;36mAutoformerForPrediction.generate\u001b[0;34m(self, past_values, past_time_features, future_time_features, past_observed_mask, static_categorical_features, static_real_features, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m   1978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m   1979\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     output_hidden_states: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1988\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleTSPredictionOutput:\n\u001b[1;32m   1989\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[39m    Greedily generate sequences of sample predictions from a model with a probability distribution head.\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[39m        multivariate predictions.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2076\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2077\u001b[0m         static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   2078\u001b[0m         static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   2079\u001b[0m         past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   2080\u001b[0m         past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   2081\u001b[0m         past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   2082\u001b[0m         future_time_features\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2083\u001b[0m         future_values\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2084\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2085\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2086\u001b[0m         return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2087\u001b[0m         use_cache\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2088\u001b[0m     )\n\u001b[1;32m   2090\u001b[0m     decoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_decoder()\n\u001b[1;32m   2091\u001b[0m     enc_last_hidden \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mencoder_last_hidden_state\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1918\u001b[0m, in \u001b[0;36mAutoformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m future_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1919\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1920\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1921\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1922\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1923\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1924\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1925\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1926\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1927\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1928\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1929\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1930\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1931\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1932\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1933\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1934\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1935\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1936\u001b[0m )\n\u001b[1;32m   1938\u001b[0m prediction_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1678\u001b[0m, in \u001b[0;36mAutoformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1671\u001b[0m     enc_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m   1672\u001b[0m         (\n\u001b[1;32m   1673\u001b[0m             transformer_inputs[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1677\u001b[0m     )\n\u001b[0;32m-> 1678\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1679\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49menc_input,\n\u001b[1;32m   1680\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1681\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1682\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1683\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1684\u001b[0m     )\n\u001b[1;32m   1685\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:1178\u001b[0m, in \u001b[0;36mAutoformerEncoder.forward\u001b[0;34m(self, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1171\u001b[0m             encoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1172\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             output_attentions,\n\u001b[1;32m   1176\u001b[0m         )\n\u001b[1;32m   1177\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m         layer_outputs \u001b[39m=\u001b[39m encoder_layer(\n\u001b[1;32m   1179\u001b[0m             hidden_states,\n\u001b[1;32m   1180\u001b[0m             attention_mask,\n\u001b[1;32m   1181\u001b[0m             layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1182\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1183\u001b[0m         )\n\u001b[1;32m   1185\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1187\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:712\u001b[0m, in \u001b[0;36mAutoformerEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[39m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39m        returned tensors for more detail.\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m--> 712\u001b[0m hidden_states, attn_weights, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    713\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    714\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    715\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    716\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    717\u001b[0m )\n\u001b[1;32m    718\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    719\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temporary/lib/python3.8/site-packages/transformers/models/autoformer/modeling_autoformer.py:630\u001b[0m, in \u001b[0;36mAutoformerAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    627\u001b[0m     \u001b[39m# used for compute values_states.roll(delay) in inference\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     tmp_values \u001b[39m=\u001b[39m value_states\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    629\u001b[0m     init_index \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 630\u001b[0m         torch\u001b[39m.\u001b[39;49marange(time_length)\n\u001b[1;32m    631\u001b[0m         \u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    632\u001b[0m         \u001b[39m.\u001b[39;49mrepeat(bsz \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads, \u001b[39m1\u001b[39;49m, channel)\n\u001b[1;32m    633\u001b[0m         \u001b[39m.\u001b[39;49mto(value_states\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    634\u001b[0m     )\n\u001b[1;32m    636\u001b[0m delays_agg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(value_states)\u001b[39m.\u001b[39mfloat()  \u001b[39m# bsz x time_length x channel\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(top_k):\n\u001b[1;32m    638\u001b[0m     \u001b[39m# compute value_states roll delay\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "device='cuda:0'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "forecasts_ = []\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts_.append(outputs.sequences.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['past_time_features', 'past_values', 'past_observed_mask', 'future_time_features'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2247, 100, 24)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "forecasts = np.vstack(forecasts_)\n",
    "print(forecasts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2247/2247 [38:09<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mase_metric = load(\"evaluate-metric/mase\")\n",
    "\n",
    "forecast_median = np.median(forecasts, 1)\n",
    "\n",
    "mase_metrics = []\n",
    "for item_id, ts in enumerate(tqdm(test_dataset)):\n",
    "    training_data = ts[\"target\"][:-prediction_length]\n",
    "    ground_truth = ts[\"target\"][-prediction_length:]\n",
    "    mase = mase_metric.compute(\n",
    "        predictions=forecast_median[item_id], \n",
    "        references=np.array(ground_truth), \n",
    "        training=np.array(training_data), \n",
    "        periodicity=get_seasonality(freq))\n",
    "    mase_metrics.append(mase[\"mase\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "test_ds = list(test_dataset)\n",
    "\n",
    "def plot(ts_index):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = pd.period_range(\n",
    "        start=test_ds[ts_index][FieldName.START],\n",
    "        periods=len(test_ds[ts_index][FieldName.TARGET]),\n",
    "        freq=test_ds[ts_index][FieldName.START].freq,\n",
    "    ).to_timestamp()\n",
    "\n",
    "    ax.plot(\n",
    "        index[-5*prediction_length:], \n",
    "        test_ds[ts_index][\"target\"][-5*prediction_length:],\n",
    "        label=\"actual\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        index[-prediction_length:], \n",
    "        np.median(forecasts[ts_index], axis=0),\n",
    "        label=\"median\",\n",
    "    )\n",
    "    \n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "plot(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2247"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
